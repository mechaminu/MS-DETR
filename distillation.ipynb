{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Deformable DETR\n",
    "# Copyright (c) 2020 SenseTime. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\n",
    "# ------------------------------------------------------------------------\n",
    "# Modified from DETR (https://github.com/facebookresearch/detr)\n",
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "import datasets.samplers as samplers\n",
    "from datasets import build_dataset, get_coco_api_from_dataset\n",
    "from engine import evaluate, train_one_epoch\n",
    "from models import build_model\n",
    "\n",
    "from main import get_args_parser, main\n",
    "\n",
    "def inference(args):\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    model, _, _ = build_model(args)\n",
    "    model.to(device)\n",
    "\n",
    "    if args.resume:\n",
    "        if args.resume.startswith('https'):\n",
    "            checkpoint = torch.hub.load_state_dict_from_url(\n",
    "                args.resume, map_location='cpu', check_hash=True)\n",
    "        else:\n",
    "            checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "\n",
    "        missing_keys, unexpected_keys = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "        unexpected_keys = [k for k in unexpected_keys if not (k.endswith('total_params') or k.endswith('total_ops'))]\n",
    "        if len(missing_keys) > 0:\n",
    "            print('Missing Keys: {}'.format(missing_keys))\n",
    "        if len(unexpected_keys) > 0:\n",
    "            print('Unexpected Keys: {}'.format(unexpected_keys))\n",
    "    model.eval()\n",
    "\n",
    "    # manually load image and preprocess for inference\n",
    "    dataset = datasets.coco.build(\"val\", args)\n",
    "\n",
    "    img, target = dataset[0]\n",
    "    \n",
    "    def denormalize(tensor, mean, std):\n",
    "        for t, m, s in zip(tensor, mean, std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "    denormalized_img = denormalize(img.clone(), [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # MS-DETR/datasets/coco.py:make_coco_transforms\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(denormalized_img.permute(1, 2, 0))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img.unsqueeze(0).to(device))\n",
    "\n",
    "    print(outputs)\n",
    "\n",
    "    # dissect outputs\n",
    "    out_logits, out_bbox = outputs['pred_logits'], outputs['pred_boxes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "coco_path=/workspace/coco2017\n",
    "num_gpus=3\n",
    "\n",
    "EXP_DIR=/workspace/ms-detr-checkpoints/ms_detr_pp_300\n",
    "\n",
    "GPUS_PER_NODE=$num_gpus ./tools/run_dist_launch.sh $num_gpus python -u main.py \\\n",
    "   --output_dir $EXP_DIR \\\n",
    "   --with_box_refine \\\n",
    "   --two_stage \\\n",
    "   --dim_feedforward 2048 \\\n",
    "   --epochs 12 \\\n",
    "   --lr_drop 11 \\\n",
    "   --coco_path=$coco_path \\\n",
    "   --num_queries 300 \\\n",
    "   --dropout 0.0 \\\n",
    "   --mixed_selection \\\n",
    "   --look_forward_twice \\\n",
    "   --use_ms_detr \\\n",
    "   --use_aux_ffn \\\n",
    "   --topk_eval 100 \\\n",
    "   --resume $EXP_DIR/checkpoint.pth \\\n",
    "   --eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('Deformable DETR training and evaluation script', parents=[get_args_parser()])\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.output_dir = r'/workspace/ms-detr-checkpoints/ms_detr_300'\n",
    "args.resume = r'/workspace/ms-detr-checkpoints/ms_detr_300/checkpoint.pth'\n",
    "args.with_box_refine = True\n",
    "args.two_stage = True\n",
    "args.dim_feedforward = 2048\n",
    "args.epochs = 12\n",
    "args.lr_drop = 11\n",
    "args.coco_path = r'/workspace/coco2017'\n",
    "args.num_queries = 300\n",
    "args.use_ms_detr = True\n",
    "args.use_aux_ffn = True\n",
    "args.topk_eval = 100\n",
    "args.eval = True\n",
    "args.inference = True\n",
    "\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "if args.inference:\n",
    "    inference(args)\n",
    "else:\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('Deformable DETR training and evaluation script', parents=[get_args_parser()])\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.output_dir = r'/workspace/ms-detr-checkpoints/ms_detr_300'\n",
    "args.resume = r'/workspace/ms-detr-checkpoints/ms_detr_300/checkpoint.pth'\n",
    "args.with_box_refine = True\n",
    "args.two_stage = True\n",
    "args.dim_feedforward = 2048\n",
    "args.epochs = 12\n",
    "args.lr_drop = 11\n",
    "args.coco_path = r'/workspace/coco'\n",
    "args.num_queries = 300\n",
    "args.use_ms_detr = True\n",
    "args.use_aux_ffn = True\n",
    "args.topk_eval = 100\n",
    "args.backbone = 'resnet18'\n",
    "args.eval = True\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "model, _, _ = build_model(args)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# Deformable DETR\n",
    "# Copyright (c) 2020 SenseTime. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# Modified from https://github.com/pytorch/pytorch/blob/173f224570017b4b1a3a1a13d0bff280a54d9cd9/torch/distributed/launch.py\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "nproc_per_node = 3\n",
    "nnodes = 1\n",
    "node_rank = 0\n",
    "training_script_command = r'''python -u main.py \\\n",
    "   --output_dir /workspace/ms-detr-checkpoints/ms_detr_300_resnet18 \\\n",
    "   --with_box_refine \\\n",
    "   --two_stage \\\n",
    "   --dim_feedforward 2048 \\\n",
    "   --epochs 12 \\\n",
    "   --lr_drop 11 \\\n",
    "   --coco_path=/workspace/coco2017 \\\n",
    "   --num_queries 300 \\\n",
    "   --use_ms_detr \\\n",
    "   --use_aux_ffn \\\n",
    "   --topk_eval 100 \\\n",
    "   --backbone resnet18\n",
    "   '''\n",
    "#    --resume /workspace/ms-detr-checkpoints/ms_detr_300/checkpoint.pth \\\n",
    "#    --eval\n",
    "\n",
    "# world size in terms of number of processes\n",
    "dist_world_size = nproc_per_node * nnodes\n",
    "\n",
    "\n",
    "# set PyTorch distributed related environmental variables\n",
    "current_env = os.environ.copy()\n",
    "current_env[\"MASTER_ADDR\"] = '127.0.0.1'\n",
    "current_env[\"MASTER_PORT\"] = '29501'\n",
    "current_env[\"WORLD_SIZE\"] = str(dist_world_size)\n",
    "\n",
    "processes = []\n",
    "\n",
    "for local_rank in range(0, nproc_per_node):\n",
    "    # each process's rank\n",
    "    dist_rank = nproc_per_node * node_rank + local_rank\n",
    "    current_env[\"RANK\"] = str(dist_rank)\n",
    "    current_env[\"LOCAL_RANK\"] = str(local_rank)\n",
    "\n",
    "    cmd = [training_script_command]\n",
    "\n",
    "    process = subprocess.Popen(cmd, shell=True, env=current_env)\n",
    "    processes.append(process)\n",
    "\n",
    "for process in processes:\n",
    "    process.wait()\n",
    "    if process.returncode != 0:\n",
    "        raise subprocess.CalledProcessError(returncode=process.returncode,\n",
    "                                            cmd=process.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "import util.misc as utils\n",
    "from datasets.coco_eval import CocoEvaluator\n",
    "from datasets.panoptic_eval import PanopticEvaluator\n",
    "from datasets.data_prefetcher import data_prefetcher\n",
    "\n",
    "def train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,\n",
    "                    data_loader: Iterable, optimizer: torch.optim.Optimizer,\n",
    "                    device: torch.device, epoch: int, max_norm: float = 0):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    metric_logger.add_meter('class_error', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))\n",
    "    metric_logger.add_meter('grad_norm', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 50\n",
    "\n",
    "    prefetcher = data_prefetcher(data_loader, device, prefetch=True)\n",
    "    samples, targets = prefetcher.next()\n",
    "\n",
    "    # for samples, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "    for _ in metric_logger.log_every(range(len(data_loader)), print_freq, header):\n",
    "        outputs = model(samples)\n",
    "        loss_dict = criterion(outputs, targets)\n",
    "        weight_dict = criterion.weight_dict\n",
    "        losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        loss_dict_reduced_unscaled = {f'{k}_unscaled': v\n",
    "                                      for k, v in loss_dict_reduced.items()}\n",
    "        loss_dict_reduced_scaled = {k: v * weight_dict[k]\n",
    "                                    for k, v in loss_dict_reduced.items() if k in weight_dict}\n",
    "        losses_reduced_scaled = sum(loss_dict_reduced_scaled.values())\n",
    "\n",
    "        loss_value = losses_reduced_scaled.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        if max_norm > 0:\n",
    "            grad_total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        else:\n",
    "            grad_total_norm = utils.get_total_grad_norm(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        metric_logger.update(loss=loss_value, **loss_dict_reduced_scaled, **loss_dict_reduced_unscaled)\n",
    "        metric_logger.update(class_error=loss_dict_reduced['class_error'])\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "        metric_logger.update(grad_norm=grad_total_norm)\n",
    "\n",
    "        samples, targets = prefetcher.next()\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
